{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54e514d-7140-47b3-989f-339d5db80ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and using a model\n",
      "using BERT, an encoding only model\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating and using a model\")\n",
    "print(\"using BERT, an encoding only model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85bdb233-8f92-42c2-bcdb-4643192ac848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655c0f98-9cc4-4291-ba32-09a9ed2e3cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print configuration options\n",
      "hidden_size attribute defines the size of the hidden_states vector\n",
      "num_hidden_layers defines the number of layers for the Transformer model\n",
      "\n",
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.42.4\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"print configuration options\")\n",
    "print(\"hidden_size attribute defines the size of the hidden_states vector\")\n",
    "print(\"num_hidden_layers defines the number of layers for the Transformer model\\n\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8890aef-482b-45d3-a3d9-c7a301c090e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model from the default configuration and initialize it with random values\n",
    "# would outout gibberish becuase it's not trained\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "config = BertConfig()\n",
    "model = BertModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c997ea8-a3da-4df6-8136-e248887c520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pretrained model\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70bd5217-8af5-41e9-b8c6-e74c926078df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved in he directory above\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model.save_pretrained(\"/m2-data/llm/models\")\n",
    "print(\"saved 2 files in the directory above\")\n",
    "print(\"414M Jul 22 18:09 model.safetensors\")\n",
    "print(\"656 Jul 22 18:09 config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38882c52-dfed-4feb-9c68-6529a08aecce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'Cool.', 'Nice!']\n"
     ]
    }
   ],
   "source": [
    "# implement inference\n",
    "# models can only process the numbers that the tokenizer generates.\n",
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "print(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c090317d-2dbf-4b66-959a-3dce6b064dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95941b6e-d94f-42dd-aefe-31b70fdbd7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to matrices format\n",
    "import torch\n",
    "\n",
    "model_inputs = torch.tensor(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9619b6f-e1ba-43fd-b6e3-d18b5bc00416",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(model_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
